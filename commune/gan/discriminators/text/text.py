import commune
import torch
import torch.nn as nn
from typing import Union, List
from transformers import AutoTokenizer, ElectraForMultipleChoice


DEFAULT_TOKENIZER = "google/electra-base-generator"


class TextDiscriminator(nn.Module, commune.Module):

    def __init__(self,  
                 discriminator : str="google/electra-base-generator", 
                 tokenizer : str= None
                 ) -> None:
        super(TextDiscriminator, self).__init__()
        self.discriminator = ElectraForMultipleChoice.from_pretrained(discriminator)
        self.tokenizer = AutoTokenizer.from_pretrained(discriminator if tokenizer == None else tokenizer)

    def set_tokenizer(self, tokenizer : str):
        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer)

    
    def set_discriminator(self, discriminator : str):
        self.discriminator = ElectraForMultipleChoice.from_pretrained(discriminator)

    def encode_text(self, 
                    prompt : Union[List[str], List[List[str]], str]=None, 
                    choices : Union[List[str], List[List[str]], str]=None,
                    **prams : dict[str, any]):
        """ This only produces only a single batch of prompt and output 
            with one as expected with intended masked values, 
            and one were it was generated by the model."""
        if self.tokenizer == None:
            self.tokenizer = AutoTokenizer.from_pretrained(DEFAULT_TOKENIZER)
        
        return self.tokenizer(prompt, choices, **prams)
    
    def tokenize_text(self, x : Union[List[str], str]):
            return self.tokenizer.tokenize(x, add_special_tokens=True, padding=True)

    def forward(self, 
                inputs : dict,
                labels : torch.Tensor):

        # CHECK 
        # FIX ME---

        if not "labels" in inputs.keys():
            inputs["labels"] = labels

        return self.discriminator(**inputs)

    __call__ = forward
    
    @classmethod
    def test_encoding(cls):
        model = cls()
        prams = dict(return_tensors= 'pt', max_length=512, truncation=True, padding='max_length')
        output = model.encode_text(["what was the fox doing", "this is another example"], ["The quick brown fox jumps over the lazy dog", "this is another example"], **prams)
        print(output.keys(), output["input_ids"].shape)

            # return isinstance(self, torch.Tensor) 
            
    @classmethod
    def test_tokenize(cls):
        model = cls()
        print(model.tokenize_text(["The quick brown fox jumps over the lazy dog", "The quick brown fox jumps over the lazy dog"], ))
        # return isinstance(self, torch.Tensor) 

    @classmethod
    def test_forward(cls):
        """ warning is telling you that some weights were randomly initialized 
            (here you classification head), which is normal since you are 
            instantiating a pretrained model for a different task. It’s there
            to remind you to finetune your model (it’s not usable for inference directly)."""
        model = cls()
        prams = dict(return_tensors= 'pt', max_length=512, truncation=True, padding='max_length')        
        prompt = "In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced."
        choice0 = "It is eaten with a fork and a knife."
        choice1 = "It is eaten while held in the hand."

        encoding = model.encode_text([prompt, prompt], [choice0, choice1], **prams)

        with torch.no_grad():
            print(model({k: v.unsqueeze(0) for k, v in encoding.items()},labels=torch.tensor(0).unsqueeze(0)))

# generative adversarial networks
if __name__ == "__main__":
    TextDiscriminator.run()